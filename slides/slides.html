<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>Testing in node.js</title>

  <meta name="description" content="A talk about helpful testing techniques for node.js apps">
  <meta name="author" content="Nicole Rauch and Andreas Leidig">

  <meta name="apple-mobile-web-app-capable" content="yes"/>
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link rel="stylesheet" href="css/reveal.min.css">
  <link rel="stylesheet" href="css/theme/sky.css" id="theme">

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="lib/css/zenburn.css">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
    if (window.location.search.match(/print-pdf/gi)) {
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = 'css/print/pdf.css';
      document.getElementsByTagName('head')[0].appendChild(link);
    }
  </script>

  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
</head>

<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">
<!-- Title page -->
<section>
  <h1>Testing in node.js</h1>

  <h3>Interesting and Helpful Techniques</h3>

  <p>
    <small>By Nicole Rauch and Andreas Leidig</small>
  </p>
</section>

<!-- CONTEXT -->
<section>
  <section>
    <h2>Context</h2>

    <ul>
      <li>Server application running on node.js</li>
      <li>Community platform</li>
      <li>2 main contributors</li>
    </ul>

    <aside class="notes"></aside>
  </section>

  <section>
    <h2>Facts</h2>

    <ul>
      <li>Live since August 2013</li>
      <li>3-tier Architecture</li>
      <li>Stateless Backend</li>
    </ul>

    <aside class="notes"></aside>
  </section>
</section>

<!-- COOL BEANS -->
<section>
  <section>
    <h2>Indirect dependencies</h2>
  
    <p>
      <b>Problem:</b> How to stub dependencies at different layers?
    </p>

    <aside class="notes">
      Hier die Slides für Cool Beans.
    </aside>
  </section>
    
  <section>
    <h2>Application Structure</h2>
      <img src="pics/MembersModule.svg">
  </section>
    
  <section>
    index.js:
    <pre class="javascript"><code data-trim contenteditable>
var service = require('./membersService');

app.get('/', function (req, res, next) {
  service.allMembers(function (err, members) {
    res.render('index', { members: members });
  });
});
    </code></pre>
      
      membersService.js:
    <pre class="javascript"><code data-trim contenteditable>
var store = require('./memberstore');

module.exports = {
  allMembers: function (callback) {
    store.allMembers(callback);
  }
};
    </code></pre>
      
      memberstore.js:
    <pre class="javascript"><code data-trim contenteditable>
var persistence = require('../persistence/persistence')('memberstore');

module.exports = {
  allMembers: function (callback) {
    persistence.list({lastname: 1, firstname: 1}, callback);
  }
};
    </code></pre>
      
      - Node.js uses <code>require</code> to load modules:
      
      (example)
    </section>  
    
    <section>
      - In different tests, we want to stub (and don't want to stub) different modules:
      Just testing one module: stub the underlying module
      Testing two modules in integration: stub the second module
      Testing three modules in integration: stub the lowest module
      
      (attention! why would we want to do this?)
    </section>
    
    <section>
      - Interesting: <code>require</code> promises a singleton module
      -> why not stub this module?
      BUT: <code>require</code> provides one singleton per import path!
      So the production import produces one instance and the test import produces A DIFFERENT instance -> bummer...
      
      - Proxyquire can replace a <code>require</code>d module.
    </section>  
        
    <section>
      So if we just test one module, we are fine:
      
      But if we test two modules in integration, things get slightly more complicated:
      
      And if we test three modules in integration, even more so:
    </section>
  
  <section>
      <h2>What would be a better solution?</h2>
      Try out
      Discuss
  </section>
    
    <section>
        <h2>Our Solution</h2>
        We decided to use...
    </section>

    <section>
        <h2>Dependency Injection</h2>
    </section>

    <section>
        A framework called <code>CoolBeans</code>
        
        We define our singleton beans:
        
        (beans.json)
        
        Plug them into nconf:
        
        (configure.js)
        
    </section>
    
    <section>
        And use them in production and test:
        
        (beans.get)
        
        In the tests, we can stub exactly the module we want:
        
        For a single layer test:
        
        For a two-layer test:
        
        For a three-layer test:
        
    </section>

</section>

<!-- NCONF -->
<section>
  <section>
    <h2>Application Configuration</h2>

    <p>
      <b>Problem:</b> We configure our application via a configuration framework. How can we provide a standardized test configuration with minimal setup?
    </p>

    <aside class="notes">
      Hier die Slides für nconf.
    </aside>
  </section>

  <section>
    <h3>Testing with dependencies on the environment?</h3>

    <p>This is not acceptable. We need to provide a standard testing configuration independent from the production configuration.</p>
    <ul>
      <li>Logging</li>
      <li>Passwords</li>
      <li>Local Paths</li>
    </ul>

    <aside class="notes">
      Anything we need to be individual depending on the environment.
    </aside>
  </section>
</section>

<!-- VARIOUS TESTING NEEDS -->
<section>
  <section>
    <h2>Testing Needs</h2>
  
    <p>
      <b>Problem:</b> The application requires different testing techniques depending on the level of testing. How to adapt to various testing needs?
    </p>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
</section>

<!-- UI tests / Application tests -->
<section>
  <section>
    <h2>UI Tests</h2>
  
    <p>
      <b>Problem:</b> How can I perform UI tests with only setting up a minimal part of the application?
    </p>

    <aside class="notes">
      Hier die Slides für app testing.
    </aside>
  </section>
</section>

<!-- DB tests -->
<section>
  <!-- VORHER: nconf -->
  <section>
    <h2>DB Tests</h2>
  
    <p>
      <b>Problem:</b> How to test a database in integration?
    </p>
    <ul>
      <li>We use native queries and other database features in our code.</li>
      <li>In our test configuration, we replace the module that connects to the database by a fake.</li>
    </ul>
    
    <ul>
      <li>Question: How to test the database integration?</li>
      <li>Question: How to test native queries?</li>
    </ul>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
  
  <section>
    <h2>DB Tests</h2>
  
    <p>
      <b>Our Solution</b>
    </p>
    <ul>
      <li>We set up a second test configuration where we connect to a test database (i.e. a special collection in our mongoDB).</li>
      <li>Nice: We cannot mess up production data even if we run the tests on the production system.</li>
    </ul>
    
    <aside class="notes">
      <p>This is our configuration for tests with DB:</p>
      <p>https://github.com/softwerkskammer/Agora/blob/master/testutil/configureForTestWithDB.js</p>
      <p>It uses the following beans definitions for the modules that connect to the database:</p>
      <p>https://github.com/softwerkskammer/Agora/blob/master/config/testbeansWithDB.json</p>
      <p>So far, only groupsPersistence, activitiesPersistence and sympaPersistence are being connected to the database; the others still point to the persistence fake because there are currently no integration tests for them.</p>
      
      <p>The actual database tests are now pretty straightforward:</p>
      <p>https://github.com/softwerkskammer/Agora/blob/master/testWithDB/activitiesDB/activities_index_upcoming_past_test.js</p>
      <p>In the setup, clear the database, persist the desired objects, run the test and check the results.</p>

    </aside>
  </section>
</section>

<!-- RACE CONDITIONS -->
<section>
  <!-- VORHER: CoolBeans App/UI Tests DB Tests -->
  <section>
    <h2>DB Race Conditions</h2>

    <p>
      <b>Problem:</b> How to test race conditions on a database?
    </p>

    <ul>
      <li>To prevent data loss due to concurrent modification of data, we use version counters.</li>
      <li>If feasible, we apply automatic retries.</li>
      <li>Otherwise, the user is asked to redo his operation.</li>
    </ul>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>

  <section>
    <h2>DB Race Conditions</h2>

    <p>
      <b>Question:</b> How can we test that
    </p>

    <ul>
      <li>there will be no data loss due to race conditions?</li>
      <li>the automatic retry succeeds?</li>
    </ul>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
  
  <section>
    <h2>DB Race Conditions</h2>

    <p>
      <b>Our Solution:</b> (No-data-loss test)
    </p>

    <ul>
      <li>Actual race condition (i.e.~interleaved load-modify-save sequence) cannot be established in automated test</li>
      <li>Trick:</li>
      <ul>
        <li>stub the load operation so that it returns the object in question <b>before</b> the concurrent modification</li>
        <li>initialize database with object in question <b>after</b> the concurrent modification</li>
        <li>this simulates that the concurrent modification takes place after the load operation but before the save operation that is performed in our test</li>
      </ul>
      <li>Test checks that the concurrent modification is still present in the object in question after the attempted save operation.</li>
    </ul>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
  
  <section>
    <h2>DB Race Conditions</h2>

    <p>
      <b>Our Solution:</b> (Automatic-retry test)
    </p>

    <ul>
      <li>To test the automatic retry:</li>
      <ul>
        <li>stub the load operation so that it returns the object in question <b>before</b> the concurrent modification on the first invocation</li>
        <li>and the object in question <b>after</b> the concurrent modification on the second invocation (i.e.~when automatic retry is triggered)</li>
      </ul>
      <li>Test checks that the modification from our test as well as the concurrent modification is present in the object in question after the save operation.</li>
    </ul>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
</section>

<!-- DOM tests-->
<section>
  <section>
    <h2>DOM Tests</h2>

    <p>
      <b>Problem:</b> How can I test frontend code that requires a DOM if all I have is jade template files (but no html files)?
    </p>

    <aside class="notes">
      Hier die Slides für DOM testing.
    </aside>
  </section>
  
  <section>
    <h2>DOM Tests</h2>

    <p>We want to unit test the client side validations. This code relies heavily on DOM elements.</p>
    <p>We do not have static html files to provide a DOM for testing. 
      All our html code is rendered at runtime from jade templates and also provided with runtime state (via fields in <code>res.locals</code>)</p>

    <aside class="notes">
      Hier die Slides für DOM testing.
    </aside>
  </section>
  
  <section>
    <h2>form.jade</h2>

    <pre class="javascript"><code data-trim contenteditable>
doctype html

html
  head
    script(src='/jquery.js')
    script(src='/jquery.validate.js')
    script(src='/check-form.js')
    title SPA fun with jade files
  body
    h1 SPA
    form#theform(action='/submit', method='post')
      label text:
      input(type='text', name='text', placeholder='text')
      button(type='submit') OK
    hr
    p The injected variable is #{val.words}
    </code></pre>
    <p>The input field is marked mandatory via JavaScript (<code>jquery-validation</code>)</p>
    <aside class="notes">
      <p>#{val.words} is the runtime state</p>
      <p>We only want to check that 'text' is mandatory</p>
    </aside>
  </section>
  
  <section>
    <h2>check-form.js</h2>

    <pre class="javascript"><code data-trim contenteditable>
var form_validator;
var initValidator = function () {
  form_validator = $('#theform').validate({
    rules: { text: 'required' },
  });
  form_validator.form();
  var handler = function (element) {
    return function () { form_validator.element(element); };
  };
  ['#theform [name=text]'].forEach(function (each) {
    $(each).keyup(handler(each));
  });
};
$(document).ready(initValidator);
    </code></pre>
  </section>
  
  <section>
    <h2>The Test</h2>

    <pre class="javascript"><code data-trim contenteditable>
describe('The Form', function () {
  var checkFieldMandatory = function (fieldname) {
    var field = $(fieldname);
    field.val('');
    expect(form_validator.element(field)).toBe(false);
    expect(form_validator.errorList[0].message)
      .toBe('This field is required.');
    field.val('.');
    expect(form_validator.element(field)).toBe(true);
  };
      
  it('checks that "text" is mandatory', function () {
    checkFieldMandatory('#theform [name=text]');
  });
});
    </code></pre>
  </section>

  <section>
    <h1>CODE</h1>
  </section>
  
  <section>
    <h2>Our Solution</h2>
    <ol>
      <li>Extract the form to a jade mixin. So it can be included easily from some other jade file.</li>
      <li>Create a new jade file including all our form mixins.</li>
      <li>Create a dummy file for all needed <code>res.locals</code> state</li>
      <li>Compile this jade file via a grunt task.</li>
    </ol>
  </section>
  
  <section>
    <h4>The Mixin</h4>
    <pre class="javascript"><code data-trim contenteditable>
mixin theform(value)
  form#theform(action='/submit', method='post')
    label text:
    input(type='text', name='text', placeholder='text')
    button(type='submit') OK
  hr
  p The injected variable is #{value.words}
    </code></pre>
    <h4>forms.jade</h4>
    <pre class="javascript"><code data-trim contenteditable>
include ../../views/form
+theform(val)
    </code></pre>
    <h4>locals</h4>
    <pre class="javascript"><code data-trim contenteditable>
module.exports = {val: {words: 'some text'}};
    </code></pre>
  </section>

  <section>
    <h2>Gruntfile</h2>
    <pre class="javascript"><code data-trim contenteditable>
jade: {
  compile: {
    options: {
      data: function () {
        // include the locals
        return require('./frontendtests/fixtures/locals');
      }
    },
    files: {
      // files to compile
      'frontendtests/fixtures/forms.html': 'frontendtests/fixtures/forms.jade'
    }
  }
}
    </code></pre>
  </section>

  <section>
    <h1>CODE</h1>
  </section>

</section>

<!-- coverage tests-->
<section>
  <section>
    <h2>Coverage Instrumentation</h2>

    <p>
      <b>Problem:</b> Coverage measure instruments all code, even if it is run inside the mongodb. Thus breaking it.
    </p>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
  
  <section>
    <h2>Overall Coverage</h2>

    <p>
      <b>Problem:</b> We have different test runs that all measure coverage. How can we get an overall coverage?
    </p>

    <aside class="notes">
      Hier die Slides.
    </aside>
  </section>
</section>

<!-- Thank You -->
<section>
<h1>
  Thank you
</h1>  
</section>

</div>

</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.min.js"></script>

<script>

  // Full list of configuration options available here:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,

    theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Parallax scrolling
    // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
    // parallaxBackgroundSize: '2100px 900px',

    // Optional libraries used to extend on reveal.js
    dependencies: [
      { src: 'lib/js/classList.js', condition: function () { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
      { src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
      { src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } },
      { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () { return !!document.body.classList; } },
      { src: 'plugin/notes/notes.js', async: true, condition: function () { return !!document.body.classList; } }
    ]
  });

</script>

</body>
</html>
